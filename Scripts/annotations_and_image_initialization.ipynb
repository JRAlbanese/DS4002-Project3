{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /home/codespace/.python/current/lib/python3.12/site-packages (2.0.8)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from pycocotools) (3.9.2)\n",
      "Requirement already satisfied: numpy in /home/codespace/.python/current/lib/python3.12/site-packages (from pycocotools) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pycocotools #our annotations are in coco json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# helpful sources for COCO: https://www.v7labs.com/blog/coco-dataset-guide\n",
    "# https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/md-coco-overview.html\n",
    "# https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "annotation_file = '../Annotations/combined_annotations.coco.json'\n",
    "coco = COCO(annotation_file)\n",
    "#now I have to make sure I get the ID for each and every image\n",
    "image_ids = coco.getImgIds()\n",
    "images = coco.loadImgs(image_ids)\n",
    "\n",
    "#preping image data for keras:\n",
    "for img in images: #iterating over each image in list of images from COCO dataset\n",
    "    image_id = img['id'] # 'id' is the unique image identifier\n",
    "    file_name = img['file_name'] #image's file name\n",
    "    \n",
    "    annotation_ids = coco.getAnnIds(imgIds=image_id) #this gets the annotation ID\"s associated with the given image in the for loop\n",
    "    the_annotations = coco.loadAnns(annotation_ids)  #loadAnns retrieves annotation data as a LIST of dictionaries\n",
    "        #each dict includes data on the image like bounding box (bbox)\n",
    "        \n",
    "    bboxes = [ann['bbox'] for ann in the_annotations]\n",
    "    \n",
    "    #print(bboxes)  ok we have a lot of different numbers here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 1601\n",
      "great, we have 1601 images in our repo!\n"
     ]
    }
   ],
   "source": [
    "#now I just want to check the total number of images we have\n",
    "import os\n",
    "image_dir = '../Image_data/DS 4002 Project 3 raw image data'\n",
    "# get a simple list of all files\n",
    "all_files = os.listdir(image_dir)\n",
    "# Filter out non-image files incase i skrewed something up\n",
    "image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "num_images = len(image_files) #this gives the total count of images we have\n",
    "print(f'Total number of images: {num_images}')\n",
    "print(\"great, we have 1601 images in our repo!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 1280\n",
      "Number of validation images: 321\n"
     ]
    }
   ],
   "source": [
    "#ok, now I'll split our data into an 20/80 train/test split using sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "print(f'Number of training images: {len(train_files)}')\n",
    "print(f'Number of validation images: {len(val_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /home/codespace/.python/current/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from opencv-python-headless) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Testing first 10 widths and heights. \n",
      " Widths: [612 262 612 612 800 480 480 600 275 612], \n",
      " Heights: [408 192 408 409 533 270 320 424 183 370]\n",
      "length of each. Length Widths: 1601, Length of Heights: 1601\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#next I'm going to use cv2, which is helpful for doing things like image resizing\n",
    "#source: https://konfuzio.com/en/cv2/#:~:text=The%20cv2%20module%20is%20the,commonly%20used%20functions%20in%20cv2.\n",
    "%pip install opencv-python-headless\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#I will start by initializing each images' width and height in a list\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for file in image_files:\n",
    "    image_path = os.path.join(image_dir, file) #make sure paths are consistent across systems, in case this is replicated elsewhere\n",
    "        #again, this is image_dir: image_dir = '../Image_data/DS 4002 Project 3 raw image data'\n",
    "    image = cv2.imread(image_path) \n",
    "        #print(image) --> did this to check, this is a 3 element list of info abt each image\n",
    "    h, w = image.shape[:2]  #for each image we get height and width, the :2 is to extract only these first two elements\n",
    "    widths.append(w)  # Add width to the list\n",
    "    heights.append(h)  # Add height to the list\n",
    "\n",
    "widths = np.array(widths)\n",
    "heights = np.array(heights)\n",
    "\n",
    "print(f\"Testing first 10 widths and heights. \\n Widths: {widths[:10]}, \\n Heights: {heights[:10]}\")\n",
    "print(f\"length of each. Length Widths: {len(widths)}, Length of Heights: {len(heights)}\")\n",
    "#ok sweet looks like everything is working thusfar. We now have the pixel widths and height for every image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram saved to ../Output/image_sizes_histogram.png\n"
     ]
    }
   ],
   "source": [
    "#now i'll make a histogram including the sizes of the images\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the outputs folder\n",
    "output_dir = '../Output'\n",
    "\n",
    "# Plot histograms of image widths and heights\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(widths, bins=30, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Image Widths')\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(heights, bins=30, color='green', alpha=0.7)\n",
    "plt.title('Distribution of Image Heights')\n",
    "plt.xlabel('Height (pixels)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the histogram to the outputs folder\n",
    "output_path = os.path.join(output_dir, 'image_sizes_histogram.png')\n",
    "plt.savefig(output_path)  # Save the plot as a PNG file\n",
    "plt.close()  # Close the plot to free memory\n",
    "\n",
    "print(f\"Histogram is visibile Output folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mode dimensions respectively: 612, 408\n",
      "\n",
      "\n",
      "the average dimensions of an image in our dataset is: \n",
      "616, 454\n"
     ]
    }
   ],
   "source": [
    "#now for some basic statistics on the images\n",
    "from scipy import stats\n",
    "\n",
    "mode_width = int(stats.mode(widths)[0])\n",
    "mode_height = int(stats.mode(heights)[0])\n",
    "print(f\"The Mode dimensions respectively: {mode_width}, {mode_height}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "avg_pxl_width = int(np.mean(widths))\n",
    "avg_pxl_height = int(np.mean(heights))\n",
    "print(f\"the average dimensions of an image in our dataset is: \\n{avg_pxl_width}, {avg_pxl_height}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
