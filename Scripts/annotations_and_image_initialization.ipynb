{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pycocotools #our annotations are in coco json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful sources for COCO: https://www.v7labs.com/blog/coco-dataset-guide\n",
    "# https://docs.aws.amazon.com/rekognition/latest/customlabels-dg/md-coco-overview.html\n",
    "# https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocotools/coco.py\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "annotation_file = '../Annotations/combined_annotations.coco.json'\n",
    "coco = COCO(annotation_file)\n",
    "#now I have to make sure I get the ID for each and every image\n",
    "image_ids = coco.getImgIds()\n",
    "images = coco.loadImgs(image_ids)\n",
    "\n",
    "#preping image data for keras:\n",
    "for img in images: #iterating over each image in list of images from COCO dataset\n",
    "    image_id = img['id'] # 'id' is the unique image identifier\n",
    "    file_name = img['file_name'] #image's file name\n",
    "    \n",
    "    annotation_ids = coco.getAnnIds(imgIds=image_id) #this gets the annotation ID\"s associated with the given image in the for loop\n",
    "    the_annotations = coco.loadAnns(annotation_ids)  #loadAnns retrieves annotation data as a LIST of dictionaries\n",
    "        #each dict includes data on the image like bounding box (bbox)\n",
    "        \n",
    "    bboxes = [ann['bbox'] for ann in the_annotations]\n",
    "    \n",
    "    #print(bboxes)  ok we have a lot of different numbers here\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now I just want to check the total number of images we have\n",
    "import os\n",
    "image_dir = '../Image_data/DS 4002 Project 3 raw image data'\n",
    "# get a simple list of all files\n",
    "all_files = os.listdir(image_dir)\n",
    "# Filter out non-image files incase i skrewed something up\n",
    "image_files = [f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "num_images = len(image_files) #this gives the total count of images we have\n",
    "print(f'Total number of images: {num_images}')\n",
    "print(\"great, we have 1601 images in our repo!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ok, now I'll split our data into an 20/80 train/test split using sklearn\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_files, val_files = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "print(f'Number of training images: {len(train_files)}')\n",
    "print(f'Number of validation images: {len(val_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#next I'm going to use cv2, which is helpful for doing things like image resizing\n",
    "#source: https://konfuzio.com/en/cv2/#:~:text=The%20cv2%20module%20is%20the,commonly%20used%20functions%20in%20cv2.\n",
    "%pip install opencv-python-headless\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#I will start by initializing each images' width and height in a list\n",
    "widths = []\n",
    "heights = []\n",
    "\n",
    "for file in image_files:\n",
    "    image_path = os.path.join(image_dir, file) #make sure paths are consistent across systems, in case this is replicated elsewhere\n",
    "        #again, this is image_dir: image_dir = '../Image_data/DS 4002 Project 3 raw image data'\n",
    "    image = cv2.imread(image_path) \n",
    "        #print(image) --> did this to check, this is a 3 element list of info abt each image\n",
    "    h, w = image.shape[:2]  #for each image we get height and width, the :2 is to extract only these first two elements\n",
    "    widths.append(w)  # Add width to the list\n",
    "    heights.append(h)  # Add height to the list\n",
    "\n",
    "widths = np.array(widths)\n",
    "heights = np.array(heights)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
